#where the kitti datasets are on Nautilus
data: 
  raw_path : '/jbk001-data1/kitti_raw'
  vo_path_kitti : '/jbk001-data1/datasets/kitti/kitti_vo/vo_dataset/sequences'
  vo_path_tum : '/jbk001-data1/datasets/tum/' # tum
#   vo_path_kitti : '/media/yoyee/Big_re/kitti/sequences'
#   vo_path : '/jbk001-data1/datasets/kitti/kitti_vo/vo_dataset/sequences' # kitti
#   vo_path : '/jbk001-data1/datasets/tum/' # tum
  procressed_data_path : '/jbk001-data1/datasets/kitti/kitti_vo/vo_dataset_processed'
  vo_gts : '/jbk001-data1/datasets/kitti/kitti_vo/vo_gts'

## debug (for training)
raw_base_dir: '/jbk001-data1/datasets/kitti/kitti_vo/vo_dataset/sequences'
prepared_base_dir: '/jbk001-data1/datasets/kitti/kitti_vo/vo_dataset_processed'
vo_gts : '/jbk001-data1/datasets/kitti/kitti_vo/vo_gts'
dataset: 'kitti_odo' #can be kitti_depth
num_scales: 1

#config details for the models
models : 
  if_pnp: False # default true
  if_deepF: True # default false
  
  attention:
    encoder_lr : 1e-5
    decoder_lr : 1e-4
  trianflow : 
    #match_num : 5000 # deprecated
    mode : 'depth_pose' 
    dataset : 'kitti_odo' 
    depth_match_num : 2000 # use by trianflow
    depth_sample_ratio : 0.20
    depth_scale : 1
    num_scales: 3
    h_flow_consist_alpha: 3.0
    h_flow_consist_beta: 0.05
    w_flow_error : 0.00
    is_frozen : True
    ransac_points : 2000 #we won't actually be using ransac (I hope at least)
    #pretrained : '/home/joshuakang/git/cvlab/SuperPnP/models/pretrained/kitti_odo.pth' 
    # pretrained : '/jbk001-data1/git/SuperPnP/TrianFlow/models/pretrained/kitti_odo.pth'
    pretrained : './pretrained/kitti_odo.pth'

  deepF:
    data:
      image:
        size: [376, 1241, 3] # The size when you DUMP the image and SIFTs (sets the limit for the saved image and SIFT)
      preprocessing:
        resize: [376, 1240] # slight different. Check if calibration matrix is fixed as well.
    model:
      name: 'GoodCorresNet_layers_deepF'
      depth: 5
      clamp_at: 0.02
      if_quality: false # True, add point confidence and ratio as inputs
      if_goodCorresArch: False
      if_lidar_corres: false
      if_img_feat: false
      if_img_des_to_pointnet: false
      quality_size: 2
      if_cpu_svd: true
      if_learn_offsets: false
      if_tri_depth: false
      if_qt_loss: false
      if_sample_loss: false
      if_SP: True # check if you are using superpoint
    training:
      learning_rate: 0.0001
      lr_decay_step: 10
      lr_decay_rate: 0.9
      seed: 0
      workers_train: 16 # 16
      workers_val: 8 # 2
      train_iter: 0
      val_interval: 1 # one validation of entire val set every N **training** steps
      val_interval_in_train: 1000
      val_batches: -1 # set to -1 to disable validation limit
      val_show_interval: 1 # one show of the current training from to Tensorboard every N training steps
      save_interval: 10

      retrain: false # don't set true; for new model
      train: false
      reset_iter: true
      ### trained results
      #pretrained: 'pretrained/deepF/baselineTrain_deepF_kitti_fLoss_v1/checkpoints/deepFNet_30000_checkpoint.pth.tar'
      #pretrained: 'logs/train_b16_fixData_v2/checkpoints/deepF_20.pth.tar'
      #pretrained: 'logs/train_b16_fixData_v4_pretrainedDeepF/checkpoints/deepF_100.pth.tar'
      pretrained: 'logs/train_b16_fixData_v5_reprojLoss/checkpoints/deepF_700.pth.tar'

    
#training hyperparameters 
prepared_base_dir: '/jbk001-data1/datasets/kitti/kitti_vo/vo_dataset_processed'
num_iterations: 200000
batch_size: 2 # 32
iter_start : 0 #place the iteration that it last stopped at here
num_workers : 6
ransac_num_matches : 1000
test_interval: 3
no_test: False
log_interval: 1
save_interval: 20
model_dir: './logs/'
multi_gpu: False
reproduce: False

lr : 0.0001
stride : 1

#general
img_hw: [256, 832]
raw_hw : [370,1226]
